<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<title>barcode scanner wasm</title>
	<style>

	</style>
</head>
<body>



<div>
	<p id="label" style ="color: red; font-size: 4em"></p >
	<video id="live" muted autoplay playsinline ></video>
	<canvas id="canvas"></canvas>
</div>

</body>

<!-- Import the javascript bundle produced by Emscripten-->
<script src="/js/a.out.js"></script>

<!-- The main 'application code' tying it all together -->
<script>


// Execute the application code when the WebAssembly module is ready.
Module.onRuntimeInitialized = async _ => {

	// wrap all C functions using cwrap. Note that we have to provide crwap with the function signature.
	const api = {
		scan_image: Module.cwrap('scan_image', '', ['number', 'number', 'number']),
		create_buffer: Module.cwrap('create_buffer', 'number', ['number', 'number']),
		destroy_buffer: Module.cwrap('destroy_buffer', '', ['number']),
	};

	const label2 = document.getElementById("label");
	const video = document.getElementById("live");
	const canvas = document.getElementById("canvas");
	const ctx = canvas.getContext('2d');



var count = 0;
video.addEventListener('play', () => {
	function step() {
		ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
		requestAnimationFrame(step);
		if ( ++count > 5)
		{
			count = 0;
			detectSymbols();
		}
	}
	requestAnimationFrame(step);
})

	//video.setAttribute('autoplay', '');
	//video.setAttribute('muted', '');
	//video.setAttribute('playsinline', '');
// open the webcam stream

		// settings for the getUserMedia call  
		const constraints = {audio: false, video: {height: 720,width:1280,facingMode: "environment",frameRate: 30}};

		//navigator.mediaDevices.enumerateDevices().then(devices=>{devices.forEach(function(device){label2.innerHTML +=device.kind+": "+device.label+" id = "+device.deviceId +'\n';});});

		navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
		// stream is a MediaStream object

			try {
				video.srcObject = stream;
			} catch (error) {
			video.src = URL.createObjectURL(stream);
			}
			// tell the canvas which resolution we ended up getting from the webcam
			const track = stream.getVideoTracks()[0];
			const actualSettings = track.getSettings();
			const { width, height } = actualSettings;
			console.log(actualSettings.width, actualSettings.height)
			canvas.width = actualSettings.width;
			canvas.height = actualSettings.height;
			//const p = api.create_buffer(width, height);
		//	label2.innerHTML = width + ' ' + height;

			video.play();

			}).catch((e) => {
				throw e
			});

function detectSymbols() {
	// grab a frame from the media source and draw it to the canvas
//	ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
	// get the image data from the canvas
	const image = ctx.getImageData(0, 0, canvas.width, canvas.height)
	// convert the image data to grayscale 
	const grayData = []
	const d = image.data;
	for (var i = 0, j = 0; i < d.length; i += 4, j++) {	
		var brightness = (3*d[i]+4*d[i+1]+d[i+2])>>>3;
        grayData[j] = brightness;
       // grayData[j+1] = brightness;
       // grayData[j+2] = brightness;
		//grayData[j] = (d[i] * 66 + d[i + 1] * 129 + d[i + 2] * 25 + 4096) >> 8;
	}
	// put the data into the allocated buffer on the wasm heap.
	const p = api.create_buffer(image.width, image.height);
	Module.HEAP8.set(grayData, p);
	// call the scanner function
	api.scan_image(p, image.width, image.height)
	// clean up 
    //(this is not really necessary in this example as we could reuse the buffer, but is used to demonstrate how you can manage Wasm heap memory from the js environment)
	api.destroy_buffer(p);
}

	function drawPoly(ctx, poly)
	{
	// drawPoly expects a flat array of coordinates forming a polygon (e.g. [x1,y1,x2,y2,... etc])
	ctx.beginPath();
	ctx.moveTo(poly[0], poly[1]);
	for (item = 2; item < poly.length - 1; item += 2) { ctx.lineTo(poly[item], poly[item + 1]) }

	ctx.lineWidth = 2;
	ctx.strokeStyle = "#FF0000";
	ctx.closePath();
	ctx.stroke();
	}

// render the string contained in the barcode as text on the canvas
function renderData(ctx, data, x, y) {
	ctx.font = "15px Arial";
	ctx.fillStyle = "red";
	ctx.fillText(data, x, y);
}

// set the function that should be called whenever a barcode is detected
Module['processResult'] = (symbol, data, polygon) => {
	console.log("Data liberated from WASM heap:")
	console.log(symbol)
	console.log(data)
	console.log(polygon)

		
label2.innerHTML = symbol + ' ' + data;
					
	 //draw the bounding polygon
//	drawPoly(ctx, polygon)

	 //render the data at the first coordinate of the polygon
	//renderData(ctx, data, polygon[0], polygon[1] - 10)
}

}
</script>

</html>